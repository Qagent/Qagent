{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qagent/Qagent/blob/main/vernacular_dependency_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0vRGgN4Srr"
      },
      "source": [
        "#Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tztUNbvaV45P",
        "outputId": "c5596462-e735-4046-8f38-aae37a82b161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1T66SGQaj8r"
      },
      "outputs": [],
      "source": [
        "!python -m pip install \"dask[complete]\"\n",
        "!pip install memory_profiler\n",
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2vUqo0FZP-z"
      },
      "source": [
        "#Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sqS-l4OEq7Xp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "import os\n",
        "from importlib import import_module\n",
        "import numpy as np\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import gc\n",
        "import itertools as it\n",
        "import collections\n",
        "import re\n",
        "import dask as dask\n",
        "import dask.delayed as chainmap\n",
        "import dask.dataframe as ditable\n",
        "import dask.bag as diarray\n",
        "import matplotlib.pyplot as plt\n",
        "from dask.diagnostics import ProgressBar\n",
        "import io\n",
        "import json\n",
        "from collections import Counter\n",
        "from memory_profiler import memory_usage\n",
        "import memory_profiler\n",
        "from dask.distributed import Client\n",
        "#import pyarrow.dataset as pydas\n",
        "%load_ext memory_profiler\n",
        "from dask import delayed\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gqgj9JSkPJrH"
      },
      "outputs": [],
      "source": [
        "pbar = ProgressBar()\n",
        "pbar.register()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiI6svyC4X6t"
      },
      "source": [
        "#Mount Db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxRI1gWcq9Bl",
        "outputId": "14744f36-e86f-4d5a-e00d-38fbf78e70a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkIM4_uxVvst"
      },
      "source": [
        "#Load data, clean text and save it to parquet files partitioned on language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-r0klhugagq"
      },
      "source": [
        "##read_data_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X4DnYRQkF2JP"
      },
      "outputs": [],
      "source": [
        "class read_data:\n",
        "  \n",
        "  def __init__(self,path):\n",
        "    self.path = path\n",
        "  \n",
        "  def to_path(self):  \n",
        "    x = self.path\n",
        "    a = re.split('/',x)\n",
        "    name = re.split('\\.',a[-1])[0]\n",
        "    d = a[:-2]\n",
        "    d = [d for d in d if d != '']\n",
        "    path = '/'+'/'.join(d)+'/'+'pre_processed_data_final'+'/'+name\n",
        "    return path\n",
        "  def read_csv(self):\n",
        "    path = self.path\n",
        "    data = ditable.read_csv(path,sep = 'rows',names = ['content'],header = None,dtype = str,assume_missing = True,engine='python' ,quotechar='\"', on_bad_lines = 'skip', skip_blank_lines = True,quoting = csv.QUOTE_MINIMAL) \n",
        "    data = data.dropna(how ='any')\n",
        "    def sanitary_check(x):\n",
        "      x = x\n",
        "      x = x.replace('<br>','.')\n",
        "      x = x.replace('<b>',' ')\n",
        "      x = x.replace('</b>',' ')\n",
        "      x = x.replace('</u>',' ')\n",
        "      x = x.replace('</i>',' ')\n",
        "      x = x.replace('<u>',' ')\n",
        "      x = x.replace('<i>',' ')\n",
        "      x = x.replace('<i>',' ')\n",
        "      x = re.sub(r'(\\?){1,}','?',x)\n",
        "      x = re.sub(r'(\\.){1,}','.',x) \n",
        "      x = re.sub(r'(\\n){1,}','\\n',x)\n",
        "      x = re.sub(r'(\\|)+','|',x)\n",
        "      x = re.sub(r'(\\!+){1,}','!',x)\n",
        "      x = re.sub(r'([\\xa0])+',' ',x)\n",
        "      new = re.sub(r',+',',',x) \n",
        "      new = re.sub(r'(\\s)+',\" \",new)\n",
        "      new = re.sub(r'(^\\s)+',\"\",new)\n",
        "      return new\n",
        "    data.content = data.content.apply(sanitary_check,meta=pd.Series(dtype = str))\n",
        "    def len_fil(x):\n",
        "      x = str(x)\n",
        "      if x == None:\n",
        "        return '<NA>'\n",
        "      elif len(x)>75:\n",
        "        return x\n",
        "      else:\n",
        "        return '<NA>'\n",
        "    data.content = data.content.apply(len_fil)\n",
        "    data = data[(data.content != '<br>') & (data.content != '<NA>') & (data.content != None)]  \n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZZxd6W9QEFw"
      },
      "source": [
        "##pre_process_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9kOrNJsNC_3J"
      },
      "outputs": [],
      "source": [
        "class pre_process(read_data):\n",
        "\n",
        "  def __init__(self,path):\n",
        "    self.path = path        \n",
        "    \n",
        "\n",
        "  def load_dict(self):\n",
        "    path = self.path\n",
        "    di_path = char_counter_class(path).char_prob()  \n",
        "    with open(di_path,'r',encoding = 'utf8') as f:\n",
        "      dic = json.load(f)\n",
        "    m = np.mean([dic[i+1][1] for i in range(len(dic)-1)])\n",
        "    std =np.std([dic[i+1][1] for i in range(len(dic)-1)])\n",
        "    score = m-std/100\n",
        "    dic = dict(dic)\n",
        "    dicti = {k:v for (k,v) in dic.items() if v > score}\n",
        "    return dicti\n",
        "\n",
        "\n",
        "  def clean_text(self):\n",
        "    from_path = self.path\n",
        "    data = read_data(from_path).read_csv() \n",
        "    to_path = read_data(from_path).to_path()\n",
        "    dicti = self.load_dict()\n",
        "    to_path = to_path+'/'+'parquet_files'\n",
        "    \n",
        "    def check_char(str_data):    \n",
        "      str_data = str_data\n",
        "      chk =[str_data[i] for i in range(len(str_data))]\n",
        "      def filt(da):\n",
        "        if da in dicti.keys():\n",
        "          return da\n",
        "        else: \n",
        "          return '[unkc]'\n",
        "      new_a = list(map(filt,chk))\n",
        "      num_unk = len([x for x in new_a if x == '[unkc]'])\n",
        "      num_chars = len(new_a)\n",
        "      if num_unk/num_chars > 0.2:\n",
        "        new_a = ['missing']\n",
        "      else:\n",
        "        new_a = new_a\n",
        "\n",
        "      new_a = \"\".join(new_a)\n",
        "      return new_a\n",
        "    def final_cleaning(x):\n",
        "      x = x\n",
        "      x = re.sub(r'(\\s)+',\" \",x)\n",
        "      x = re.sub(r'(\\.)+',\" . \",x)\n",
        "      x = re.sub(r'(\\|)',\" | \",x)\n",
        "      x = re.sub(r'(\\?)',\" ? \",x)\n",
        "      x = re.sub(r'(\\!)',\" ! \",x)\n",
        "      x = re.sub(r'(\\[unkc\\])+',\"[unkc]\",x)\n",
        "      return x\n",
        "    def bow(a1):\n",
        "      a = a1\n",
        "      b = re.split('[(\\s|,|\\||\\.|\\?)]+',a)\n",
        "      b = [b.lower().strip() for b in b if b != ''and b != ' 'and b != ' \"\" '] \n",
        "      data = b\n",
        "      return data \n",
        "    def sentence(a1):\n",
        "      a = a1\n",
        "      b = re.split('[(|\\||\\.|\\?)]+',a)\n",
        "      b = [b.lower().strip() for b in b if b != ''and b != ' ' and b != ' \"\" '] \n",
        "      return b  \n",
        "    data.content = data.content.apply(check_char,meta=pd.Series(dtype = str))\n",
        "    data.content = data.content.apply(final_cleaning,meta=pd.Series(dtype = str))\n",
        "    data = data[(data.content != '') & (data.content != None) & (data.content != 'missing')]\n",
        "    data['bow'] = data.content.map(bow,meta = pd.Series(dtype = str))\n",
        "    data['sentence'] = data.content.map(sentence,meta = pd.Series(dtype = str))\n",
        "    data.to_parquet(to_path, engine = 'pyarrow',write_index = False,compute = False).compute(scheduler = 'distributed')\n",
        "    gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##char_counter_class"
      ],
      "metadata": {
        "id": "FcEK6fxR3DQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class char_counter_class(pre_process):\n",
        "  def __init__(self,path):                      \n",
        "    super().__init__(path)\n",
        "    self.path = path  \n",
        "  \n",
        "  \n",
        "  def char_prob(self):\n",
        "    path = self.path\n",
        "    to_path = read_data(path).to_path()\n",
        "    to_path = to_path+'/'+'char_prob'\n",
        "    fname = to_path+'/'+'char_prob.json'\n",
        "    data = read_data(path).read_csv()\n",
        "    data = data.repartition(npartitions = 24)\n",
        "    data = data.persist(scheduler = 'distributed',optimize_graph = True)\n",
        "    data_dic = data.content\n",
        "    data_dic = data_dic.sample(frac = 0.4,random_state = 1)\n",
        "    dict_data = diarray.from_sequence(data_dic).flatten().frequencies(sort = True).compute(scheduler = 'processes')  \n",
        "    l = sum([dict_data[i][1 ]for i in range(len(dict_data))])\n",
        "    prob = [dict_data[i][1]/l for i in range(len(dict_data))]\n",
        "    dict_key = [dict_data[i][0] for i in range(len(dict_data))]\n",
        "    dict_data = list(tuple(zip(dict_key,prob)))\n",
        "    if not os.path.exists(to_path):\n",
        "      os.makedirs(to_path)\n",
        "    with open(fname, 'w', encoding='utf-8') as f:\n",
        "      json.dump(dict_data, f, ensure_ascii = False)\n",
        "    return fname\n",
        "\n"
      ],
      "metadata": {
        "id": "OLKdvdonyEYw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Code"
      ],
      "metadata": {
        "id": "AMnnQ2IXXaJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dask.distributed import Client\n",
        "client = Client(processes = True)\n",
        "client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "k7W-Bq49jwkv",
        "outputId": "a0ea2c75-e972-4ac3-9ac4-a8f8be8b728c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:43497' processes=4 threads=8, memory=54.76 GB>"
            ],
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:43497</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>4</li>\n",
              "  <li><b>Cores: </b>8</li>\n",
              "  <li><b>Memory: </b>54.76 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time eng = pre_process('/content/drive/My Drive/DataNew/prenglish.csv').clean_text()\n",
        "%time od = pre_process('/content/drive/My Drive/DataNew/prodia.csv').clean_text()\n",
        "%time ur = pre_process('/content/drive/My Drive/DataNew/prurdu.csv').clean_text()\n",
        "%time pu = pre_process('/content/drive/My Drive/DataNew/prpunjabi.csv').clean_text()\n",
        "%time be = pre_process('/content/drive/My Drive/DataNew/prbengali.csv').clean_text()\n",
        "%time ta = pre_process('/content/drive/My Drive/DataNew/prtamil.csv').clean_text()\n",
        "%time mar = pre_process('/content/drive/My Drive/DataNew/prmarathi.csv').clean_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWa7RZDzE5AS",
        "outputId": "9c0a826d-b7ef-42d7-d074-6b9d1fbcedc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[########################################] | 100% Completed |  4.8s\n",
            "CPU times: user 15.6 s, sys: 3.03 s, total: 18.6 s\n",
            "Wall time: 2min 52s\n",
            "[########################################] | 100% Completed |  6.4s\n",
            "CPU times: user 20.8 s, sys: 2.76 s, total: 23.5 s\n",
            "Wall time: 3min 11s\n",
            "[########################################] | 100% Completed |  3.3s\n",
            "CPU times: user 10.4 s, sys: 1.77 s, total: 12.2 s\n",
            "Wall time: 1min 57s\n",
            "[########################################] | 100% Completed |  3.2s\n",
            "CPU times: user 10.9 s, sys: 1.66 s, total: 12.6 s\n",
            "Wall time: 1min 53s\n",
            "[########################################] | 100% Completed | 44.7s\n",
            "CPU times: user 2min 28s, sys: 22.1 s, total: 2min 51s\n",
            "Wall time: 23min 23s\n",
            "[########################################] | 100% Completed | 41.6s\n",
            "CPU times: user 1min 56s, sys: 21.5 s, total: 2min 17s\n",
            "Wall time: 19min 25s\n",
            "[########################################] | 100% Completed | 36.7s\n",
            "CPU times: user 1min 48s, sys: 16.9 s, total: 2min 5s\n",
            "Wall time: 18min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time hi = pre_process('/content/drive/My Drive/DataNew/prhindi.csv').clean_text()\n",
        "%time mal = pre_process('/content/drive/My Drive/DataNew/prmalyali.csv').clean_text()"
      ],
      "metadata": {
        "id": "gVl5dq3SSIUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPUHmY3Xddn"
      },
      "source": [
        "##Delete 0 byte files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLSKXHZ-mbig"
      },
      "outputs": [],
      "source": [
        "!find -name 'file*' -size 0 -delete"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "vernacular_dependency_parser.ipynb",
      "provenance": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}