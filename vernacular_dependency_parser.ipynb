{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qagent/Qagent/blob/main/vernacular_dependency_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0vRGgN4Srr"
      },
      "source": [
        "#Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tztUNbvaV45P",
        "outputId": "c5596462-e735-4046-8f38-aae37a82b161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1T66SGQaj8r",
        "outputId": "94707e5f-3f59-48a9-fe3d-215fa6e8c5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 30.2 MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 79.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.0)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (4.1.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (5.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.11.3)\n",
            "Collecting cloudpickle>=0.2.1\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.0.4)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.1.1-py3-none-any.whl (830 kB)\n",
            "\u001b[K     |████████████████████████████████| 830 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.2.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.7.0)\n",
            "  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 55.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 79.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 62.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 81.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 73.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.10.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 72.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 72.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 72.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
            "\u001b[K     |████████████████████████████████| 778 kB 67.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.0-py3-none-any.whl (776 kB)\n",
            "\u001b[K     |████████████████████████████████| 776 kB 60.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 71.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.1-py3-none-any.whl (766 kB)\n",
            "\u001b[K     |████████████████████████████████| 766 kB 63.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 75.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 77.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.1-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 71.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.0-py3-none-any.whl (715 kB)\n",
            "\u001b[K     |████████████████████████████████| 715 kB 77.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.1-py3-none-any.whl (705 kB)\n",
            "\u001b[K     |████████████████████████████████| 705 kB 75.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 66.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 58.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.0-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 81.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.1-py3-none-any.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 76.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 77.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.2.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 67.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.1-py3-none-any.whl (672 kB)\n",
            "\u001b[K     |████████████████████████████████| 672 kB 78.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.0-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 80.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2020.12.0-py3-none-any.whl (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 83.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 82.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0->dask[complete]) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[complete]) (2022.1)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]) (1.0.1)\n",
            "Installing collected packages: locket, cloudpickle, partd, fsspec, distributed\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.1.0 distributed-2.30.1 fsspec-2022.5.0 locket-1.0.0 partd-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31284 sha256=913a8e74007077e5716a3206d96174e5e40056c9cab64254ac5eacf0a4a715d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-0.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting cramjam>=2.3.0\n",
            "  Downloading cramjam-2.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.21.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from fastparquet) (2022.5.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->fastparquet) (1.15.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.5.0 fastparquet-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install \"dask[complete]\"\n",
        "!pip install memory_profiler\n",
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2vUqo0FZP-z"
      },
      "source": [
        "#Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sqS-l4OEq7Xp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "import os\n",
        "from importlib import import_module\n",
        "import numpy as np\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import gc\n",
        "import itertools as it\n",
        "import collections\n",
        "import re\n",
        "import dask as dask\n",
        "import dask.delayed as chainmap\n",
        "import dask.dataframe as ditable\n",
        "import dask.bag as diarray\n",
        "import matplotlib.pyplot as plt\n",
        "from dask.diagnostics import ProgressBar\n",
        "import io\n",
        "import json\n",
        "from collections import Counter\n",
        "from memory_profiler import memory_usage\n",
        "import memory_profiler\n",
        "from dask.distributed import Client\n",
        "#import pyarrow.dataset as pydas\n",
        "%load_ext memory_profiler\n",
        "from dask import delayed\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gqgj9JSkPJrH"
      },
      "outputs": [],
      "source": [
        "pbar = ProgressBar()\n",
        "pbar.register()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiI6svyC4X6t"
      },
      "source": [
        "#Mount Db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxRI1gWcq9Bl",
        "outputId": "14744f36-e86f-4d5a-e00d-38fbf78e70a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkIM4_uxVvst"
      },
      "source": [
        "#Load data, clean text and save it to parquet files partitioned on language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-r0klhugagq"
      },
      "source": [
        "##read_data_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X4DnYRQkF2JP"
      },
      "outputs": [],
      "source": [
        "class read_data:\n",
        "  \n",
        "  def __init__(self,path):\n",
        "    self.path = path\n",
        "  \n",
        "  def to_path(self):  \n",
        "    x = self.path\n",
        "    a = re.split('/',x)\n",
        "    name = re.split('\\.',a[-1])[0]\n",
        "    d = a[:-2]\n",
        "    d = [d for d in d if d != '']\n",
        "    path = '/'+'/'.join(d)+'/'+'pre_processed_data_final'+'/'+name\n",
        "    return path\n",
        "  def read_csv(self):\n",
        "    path = self.path\n",
        "    data = ditable.read_csv(path,sep = 'rows',names = ['content'],header = None,dtype = str,assume_missing = True,engine='python' ,quotechar='\"', on_bad_lines = 'skip', skip_blank_lines = True,quoting = csv.QUOTE_MINIMAL) \n",
        "    data = data.dropna(how ='any')\n",
        "    def sanitary_check(x):\n",
        "      x = x\n",
        "      x = x.replace('<br>','.')\n",
        "      x = x.replace('<b>',' ')\n",
        "      x = x.replace('</b>',' ')\n",
        "      x = x.replace('</u>',' ')\n",
        "      x = x.replace('</i>',' ')\n",
        "      x = x.replace('<u>',' ')\n",
        "      x = x.replace('<i>',' ')\n",
        "      x = x.replace('<i>',' ')\n",
        "      x = re.sub(r'(\\?){1,}','?',x)\n",
        "      x = re.sub(r'(\\.){1,}','.',x) \n",
        "      x = re.sub(r'(\\n){1,}','\\n',x)\n",
        "      x = re.sub(r'(\\|)+','|',x)\n",
        "      x = re.sub(r'(\\!+){1,}','!',x)\n",
        "      x = re.sub(r'([\\xa0])+',' ',x)\n",
        "      new = re.sub(r',+',',',x) \n",
        "      new = re.sub(r'(\\s)+',\" \",new)\n",
        "      new = re.sub(r'(^\\s)+',\"\",new)\n",
        "      return new\n",
        "    data.content = data.content.apply(sanitary_check,meta=pd.Series(dtype = str))\n",
        "    def len_fil(x):\n",
        "      x = str(x)\n",
        "      if x == None:\n",
        "        return '<NA>'\n",
        "      elif len(x)>75:\n",
        "        return x\n",
        "      else:\n",
        "        return '<NA>'\n",
        "    data.content = data.content.apply(len_fil)\n",
        "    data = data[(data.content != '<br>') & (data.content != '<NA>') & (data.content != None)]  \n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZZxd6W9QEFw"
      },
      "source": [
        "##pre_process_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9kOrNJsNC_3J"
      },
      "outputs": [],
      "source": [
        "class pre_process(read_data):\n",
        "\n",
        "  def __init__(self,path):\n",
        "    self.path = path        \n",
        "    \n",
        "\n",
        "  def load_dict(self):\n",
        "    path = self.path\n",
        "    di_path = char_counter_class(path).char_prob()  \n",
        "    with open(di_path,'r',encoding = 'utf8') as f:\n",
        "      dic = json.load(f)\n",
        "    m = np.mean([dic[i+1][1] for i in range(len(dic)-1)])\n",
        "    std =np.std([dic[i+1][1] for i in range(len(dic)-1)])\n",
        "    score = m-std/100\n",
        "    dic = dict(dic)\n",
        "    dicti = {k:v for (k,v) in dic.items() if v > score}\n",
        "    return dicti\n",
        "\n",
        "\n",
        "  def clean_text(self):\n",
        "    from_path = self.path\n",
        "    data = read_data(from_path).read_csv() \n",
        "    to_path = read_data(from_path).to_path()\n",
        "    dicti = self.load_dict()\n",
        "    to_path = to_path+'/'+'parquet_files'\n",
        "    \n",
        "    def check_char(str_data):    \n",
        "      str_data = str_data\n",
        "      chk =[str_data[i] for i in range(len(str_data))]\n",
        "      def filt(da):\n",
        "        if da in dicti.keys():\n",
        "          return da\n",
        "        else: \n",
        "          return '[unkc]'\n",
        "      new_a = list(map(filt,chk))\n",
        "      num_unk = len([x for x in new_a if x == '[unkc]'])\n",
        "      num_chars = len(new_a)\n",
        "      if num_unk/num_chars > 0.2:\n",
        "        new_a = ['missing']\n",
        "      else:\n",
        "        new_a = new_a\n",
        "\n",
        "      new_a = \"\".join(new_a)\n",
        "      return new_a\n",
        "    def final_cleaning(x):\n",
        "      x = x\n",
        "      x = re.sub(r'(\\s)+',\" \",x)\n",
        "      x = re.sub(r'(\\.)+',\" . \",x)\n",
        "      x = re.sub(r'(\\|)',\" | \",x)\n",
        "      x = re.sub(r'(\\?)',\" ? \",x)\n",
        "      x = re.sub(r'(\\!)',\" ! \",x)\n",
        "      x = re.sub(r'(\\[unkc\\])+',\"[unkc]\",x)\n",
        "      return x\n",
        "    def bow(a1):\n",
        "      a = a1\n",
        "      b = re.split('[(\\s|,|\\||\\.|\\?)]+',a)\n",
        "      b = [b.lower().strip() for b in b if b != ''and b != ' 'and b != ' \"\" '] \n",
        "      data = b\n",
        "      return data \n",
        "    def sentence(a1):\n",
        "      a = a1\n",
        "      b = re.split('[(|\\||\\.|\\?)]+',a)\n",
        "      b = [b.lower().strip() for b in b if b != ''and b != ' ' and b != ' \"\" '] \n",
        "      return b  \n",
        "    data.content = data.content.apply(check_char,meta=pd.Series(dtype = str))\n",
        "    data.content = data.content.apply(final_cleaning,meta=pd.Series(dtype = str))\n",
        "    data = data[(data.content != '') & (data.content != None) & (data.content != 'missing')]\n",
        "    data['bow'] = data.content.map(bow,meta = pd.Series(dtype = str))\n",
        "    data['sentence'] = data.content.map(sentence,meta = pd.Series(dtype = str))\n",
        "    data.to_parquet(to_path, engine = 'pyarrow',write_index = False,compute = False).compute(scheduler = 'distributed')\n",
        "    gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##char_counter_class"
      ],
      "metadata": {
        "id": "FcEK6fxR3DQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class char_counter_class(pre_process):\n",
        "  def __init__(self,path):                      \n",
        "    super().__init__(path)\n",
        "    self.path = path  \n",
        "  \n",
        "  \n",
        "  def char_prob(self):\n",
        "    path = self.path\n",
        "    to_path = read_data(path).to_path()\n",
        "    to_path = to_path+'/'+'char_prob'\n",
        "    fname = to_path+'/'+'char_prob.json'\n",
        "    data = read_data(path).read_csv()\n",
        "    data = data.repartition(npartitions = 24)\n",
        "    data = data.persist(scheduler = 'distributed',optimize_graph = True)\n",
        "    data_dic = data.content\n",
        "    data_dic = data_dic.sample(frac = 0.4,random_state = 1)\n",
        "    dict_data = diarray.from_sequence(data_dic).flatten().frequencies(sort = True).compute(scheduler = 'processes')  \n",
        "    l = sum([dict_data[i][1 ]for i in range(len(dict_data))])\n",
        "    prob = [dict_data[i][1]/l for i in range(len(dict_data))]\n",
        "    dict_key = [dict_data[i][0] for i in range(len(dict_data))]\n",
        "    dict_data = list(tuple(zip(dict_key,prob)))\n",
        "    if not os.path.exists(to_path):\n",
        "      os.makedirs(to_path)\n",
        "    with open(fname, 'w', encoding='utf-8') as f:\n",
        "      json.dump(dict_data, f, ensure_ascii = False)\n",
        "    return fname\n",
        "\n"
      ],
      "metadata": {
        "id": "OLKdvdonyEYw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Code"
      ],
      "metadata": {
        "id": "AMnnQ2IXXaJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dask.distributed import Client\n",
        "client = Client(processes = True)\n",
        "client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "k7W-Bq49jwkv",
        "outputId": "a0ea2c75-e972-4ac3-9ac4-a8f8be8b728c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:43497' processes=4 threads=8, memory=54.76 GB>"
            ],
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:43497</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>4</li>\n",
              "  <li><b>Cores: </b>8</li>\n",
              "  <li><b>Memory: </b>54.76 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time eng = pre_process('/content/drive/My Drive/DataNew/prenglish.csv').clean_text()\n",
        "%time od = pre_process('/content/drive/My Drive/DataNew/prodia.csv').clean_text()\n",
        "%time ur = pre_process('/content/drive/My Drive/DataNew/prurdu.csv').clean_text()\n",
        "%time pu = pre_process('/content/drive/My Drive/DataNew/prpunjabi.csv').clean_text()\n",
        "%time be = pre_process('/content/drive/My Drive/DataNew/prbengali.csv').clean_text()\n",
        "%time ta = pre_process('/content/drive/My Drive/DataNew/prtamil.csv').clean_text()\n",
        "%time mar = pre_process('/content/drive/My Drive/DataNew/prmarathi.csv').clean_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWa7RZDzE5AS",
        "outputId": "9c0a826d-b7ef-42d7-d074-6b9d1fbcedc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[########################################] | 100% Completed |  4.8s\n",
            "CPU times: user 15.6 s, sys: 3.03 s, total: 18.6 s\n",
            "Wall time: 2min 52s\n",
            "[########################################] | 100% Completed |  6.4s\n",
            "CPU times: user 20.8 s, sys: 2.76 s, total: 23.5 s\n",
            "Wall time: 3min 11s\n",
            "[########################################] | 100% Completed |  3.3s\n",
            "CPU times: user 10.4 s, sys: 1.77 s, total: 12.2 s\n",
            "Wall time: 1min 57s\n",
            "[########################################] | 100% Completed |  3.2s\n",
            "CPU times: user 10.9 s, sys: 1.66 s, total: 12.6 s\n",
            "Wall time: 1min 53s\n",
            "[########################################] | 100% Completed | 44.7s\n",
            "CPU times: user 2min 28s, sys: 22.1 s, total: 2min 51s\n",
            "Wall time: 23min 23s\n",
            "[########################################] | 100% Completed | 41.6s\n",
            "CPU times: user 1min 56s, sys: 21.5 s, total: 2min 17s\n",
            "Wall time: 19min 25s\n",
            "[########################################] | 100% Completed | 36.7s\n",
            "CPU times: user 1min 48s, sys: 16.9 s, total: 2min 5s\n",
            "Wall time: 18min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time hi = pre_process('/content/drive/My Drive/DataNew/prhindi.csv').clean_text()\n",
        "%time mal = pre_process('/content/drive/My Drive/DataNew/prmalyali.csv').clean_text()"
      ],
      "metadata": {
        "id": "gVl5dq3SSIUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPUHmY3Xddn"
      },
      "source": [
        "##Delete 0 byte files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLSKXHZ-mbig"
      },
      "outputs": [],
      "source": [
        "!find -name 'file*' -size 0 -delete"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "vernacular_dependency_parser.ipynb",
      "provenance": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}